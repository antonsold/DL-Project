{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import dlc_practical_prologue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "\n",
    "x_train, y_train, y_train_classes, x_test, y_test, y_test_classes = \\\n",
    "dlc_practical_prologue.generate_pair_sets(N)\n",
    "\n",
    "assert x_train.shape == torch.Size([N, 2, 14, 14])    # float32\n",
    "assert y_train.shape == torch.Size([N])               # int64\n",
    "assert y_train_classes.shape == torch.Size([N, 2])    # int64\n",
    "\n",
    "assert x_test.shape == torch.Size([N, 2, 14, 14])\n",
    "assert y_test.shape == torch.Size([N])\n",
    "assert y_test_classes.shape == torch.Size([N, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(x):\n",
    "    return sum(x)/len(x)\n",
    "\n",
    "def var(x):\n",
    "    u = mean(x)\n",
    "    return sum([(v-u)**2 for v in x])/len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_parameters(model):   # Returns the number of parameter of a given model\n",
    "    return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61935\n"
     ]
    }
   ],
   "source": [
    "## Is a Multi Layer Perceptron, composed of fully connected linear layers.\n",
    "## works well with lr=0.001  \n",
    "\n",
    "class model_0(nn.Module):   \n",
    "    def __init__(self, ns = [392,138,55,1]):\n",
    "        super().__init__()\n",
    "        layers = [nn.Linear(n_in, n_out) for n_in, n_out in zip(ns[:-1], ns[1:])]   \n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x,1)          # flatten the 2 images in one vector (but keeping batch size)\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = layer(x).relu()\n",
    "            \n",
    "        x = self.layers[-1](x) \n",
    "        x = torch.flatten(torch.sigmoid(x))\n",
    "        return x\n",
    "print(number_parameters(model_0()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56273\n"
     ]
    }
   ],
   "source": [
    "## Is a convolutional neural network poorly paramztrized\n",
    "## works well with lr=0.0001      \n",
    "\n",
    "class model_1(nn.Module):                 \n",
    "    def __init__(self):\n",
    "        super(model_1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 16, kernel_size=3, stride =1)        \n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride =1) \n",
    "\n",
    "        self.dense1 = nn.Linear(800, 64)\n",
    "        self.dense2 = nn.Linear(64, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, kernel_size=2)        \n",
    "        \n",
    "        x = F.relu(self.dense1(torch.flatten(x, 1)))\n",
    "        x = torch.flatten(torch.sigmoid(self.dense2(x)))\n",
    "        return x\n",
    "    \n",
    "print(number_parameters(model_1()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64741\n"
     ]
    }
   ],
   "source": [
    "## Is a convolutional neural network more paramztrized\n",
    "## works well with lr=0.0001      \n",
    "\n",
    "\n",
    "class model_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(model_2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 20, kernel_size=5, padding=2)        \n",
    "        self.conv2 = nn.Conv2d(20, 40, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv2d(40, 20, kernel_size=5, padding=2)\n",
    "        self.conv4 = nn.Conv2d(20, 40, kernel_size=5, padding=2)\n",
    "\n",
    "        self.dense1 = nn.Linear(360, 10)\n",
    "        self.dense2 = nn.Linear(10, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), kernel_size=2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(self.conv4(x), kernel_size=2)        \n",
    "        \n",
    "        x = F.relu(self.dense1(torch.flatten(x, 1)))\n",
    "        x = torch.flatten(torch.sigmoid(self.dense2(x)))\n",
    "        return x\n",
    "\n",
    "print(number_parameters(model_2()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25161\n"
     ]
    }
   ],
   "source": [
    "## Is a convolutional neural network that splits the input in 2 images\n",
    "##   and treats them identically and independantly \n",
    "## works well with lr=0.0001    \n",
    "\n",
    "class model_weight_sharing(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(model_weight_sharing, self).__init__()        \n",
    "        self.conv1 = nn.Conv2d(1, 20, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(20, 40, kernel_size=3)       \n",
    "        self.conv3 = nn.Conv2d(40, 40, kernel_size=3)       \n",
    "\n",
    "        self.dense1 = nn.Linear(80, 40)                     \n",
    "        self.dense2 = nn.Linear(40, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        d1 = F.relu(self.conv1(x[:, 0:1, ...]))\n",
    "        d1 = F.max_pool2d(self.conv2(d1), kernel_size=2)\n",
    "        d1 = F.max_pool2d(self.conv3(d1), kernel_size=2)\n",
    "        d1 = torch.flatten(d1, 1)\n",
    "        \n",
    "        d2 = F.relu(self.conv1(x[:, 1:2, ...]))\n",
    "        d2 = F.max_pool2d(self.conv2(d2), kernel_size=2)\n",
    "        d2 = F.max_pool2d(self.conv3(d2), kernel_size=2)\n",
    "        d2 = torch.flatten(d2, 1)\n",
    "\n",
    "        x = torch.cat((d1, d2), 1)\n",
    "        x = F.relu(self.dense1(torch.flatten(x, 1)))\n",
    "        x = torch.flatten(torch.sigmoid(self.dense2(x)))\n",
    "        return x \n",
    "    \n",
    "print(number_parameters(model_weight_sharing()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25983\n"
     ]
    }
   ],
   "source": [
    "## Is a convolutional neural network that splits the input in 2 images\n",
    "#    and trat them identically and independantly \n",
    "#    additionally, predictions about digits are returned for auxiliary losses\n",
    "## works well with lr=0.0001    \n",
    "\n",
    "class model_weight_sharing_with_auxiliary_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(model_weight_sharing_with_auxiliary_loss, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, kernel_size=3)        \n",
    "        self.conv2 = nn.Conv2d(20, 40, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(40, 40, kernel_size=3)\n",
    "        \n",
    "        #Treatment of the auxiliary outputs (classifier for both digits)\n",
    "        self.dense1_digit = nn.Linear(40, 32)\n",
    "        self.dense2_digit = nn.Linear(32, 10)\n",
    "        \n",
    "        #Tratment of the final output \n",
    "        self.dense1 = nn.Linear(80, 30)\n",
    "        self.dense2 = nn.Linear(30, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        d1 = F.relu(self.conv1(x[:, 0:1, ...]))\n",
    "        d1 = F.max_pool2d(self.conv2(d1), kernel_size=2)\n",
    "        d1 = F.max_pool2d(self.conv3(d1), kernel_size=2)\n",
    "        d1 = torch.flatten(d1, 1)\n",
    "\n",
    "        d2 = F.relu(self.conv1(x[:, 1:2, ...]))\n",
    "        d2 = F.max_pool2d(self.conv2(d2), kernel_size=2)\n",
    "        d2 = F.max_pool2d(self.conv3(d2), kernel_size=2)\n",
    "        d2 = torch.flatten(d2, 1)\n",
    "        \n",
    "        x = torch.cat((d1, d2), 1)\n",
    "        \n",
    "        d1 = F.relu(self.dense1_digit(d1))\n",
    "        d1 = F.softmax(self.dense2_digit(d1), -1)\n",
    "        d2 = F.relu(self.dense1_digit(d2))\n",
    "        d2 = F.softmax(self.dense2_digit(d2), -1)\n",
    "\n",
    "        x = F.relu(self.dense1(torch.flatten(x, 1)))\n",
    "        x = torch.flatten(torch.sigmoid(self.dense2(x)))\n",
    "        \n",
    "        return x, d1, d2 \n",
    "    \n",
    "print(number_parameters(model_weight_sharing_with_auxiliary_loss()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84362\n"
     ]
    }
   ],
   "source": [
    "## Is a convolutional neural network more paramztrized\n",
    "## works well with lr=0.0001      \n",
    "# Makes sense for deep networks !!! (to avoid vanishing gradient) <TODO> with or without WS for classifier ??\n",
    "\n",
    "class model_auxiliary_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(model_auxiliary_loss, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 20, kernel_size=5, padding=2)        \n",
    "        self.conv2 = nn.Conv2d(20, 40, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv2d(40, 20, kernel_size=5, padding=2)\n",
    "        self.conv4 = nn.Conv2d(20, 40, kernel_size=5, padding=2)\n",
    "        \n",
    "        self.dense1_ = nn.Linear(1960, 10)\n",
    "        self.dense2_ = nn.Linear(10, 1)\n",
    "        \n",
    "        self.dense1 = nn.Linear(360, 10)\n",
    "        self.dense2 = nn.Linear(10, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), kernel_size=2)\n",
    "        \n",
    "        x_ = F.relu(self.dense1_(torch.flatten(x, 1)))       #For the auxiliary output\n",
    "        x_ = torch.flatten(torch.sigmoid(self.dense2_(x_)))\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(self.conv4(x), kernel_size=2)        \n",
    "        \n",
    "        x = F.relu(self.dense1(torch.flatten(x, 1)))\n",
    "        x = torch.flatten(torch.sigmoid(self.dense2(x)))\n",
    "        return x, x_\n",
    "\n",
    "print(number_parameters(model_auxiliary_loss()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class model_auxiliary_loss_ws(nn.Module):\n",
    "#    def __init__(self):\n",
    "#        super(model_auxiliary_loss_ws, self).__init__()\n",
    "#        self.conv1 = nn.Conv2d(1, 20, kernel_size=3)   #2*14*14 => 10*12*12  (Maxpool => 10*6*6)  \n",
    "#        self.conv2 = nn.Conv2d(20, 40, kernel_size=3)  #10*6*6 => 10* 4 * 4 (Maxpool => 10*2*2)\n",
    "#        self.conv3 = nn.Conv2d(40, 60, kernel_size=3)\n",
    "#        self.conv4 = nn.Conv2d(60, 40, kernel_size=3)\n",
    "#        \n",
    "#        self.dense_digits = nn.Linear(360, 10)\n",
    "#        \n",
    "#        self.dense1 = nn.Linear(360, 10)\n",
    "#        self.dense2 = nn.Linear(10, 1)\n",
    "#        \n",
    "#    def forward(self, x):\n",
    "#        x1 = F.relu(self.conv1(x[:, 0:1, ...]))\n",
    "#        x1 = F.relu(self.conv2(x1))\n",
    "#        x1 = F.relu(self.conv3(x1))\n",
    "#        x1 = F.max_pool2d(self.conv4(x1), kernel_size=2)\n",
    "#        x1 = torch.flatten(x1, 1)\n",
    "#        \n",
    "#        x2 = F.relu(self.conv1(x[:, 1:2, ...]))\n",
    "#        x2 = F.relu(self.conv2(x2))\n",
    "#        x2 = F.relu(self.conv3(x2))\n",
    "#        x2 = F.max_pool2d(self.conv4(x2), kernel_size=2)\n",
    "#        x2 = torch.flatten(x1, 1)\n",
    "#        \n",
    "#        x = torch.flatten(x, 1)\n",
    "#        \n",
    "#        self.digits1 = F.softmax((self.dense_digits(x1)), -1)\n",
    "#        self.digits2 = F.softmax((self.dense_digits(x2)), -1)\n",
    "#        \n",
    "#        return (torch.argmax(self.digits1, axis = 1) < torch.argmax(self.digits2, axis = 1)).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class model_auxiliary_loss_2(nn.Module):\n",
    "#    def __init__(self):\n",
    "#        super(model_auxiliary_loss_2, self).__init__()\n",
    "#        self.conv1 = nn.Conv2d(2, 20, kernel_size=3, padding=2)   #2*14*14 => 10*12*12  (Maxpool => 10*6*6)  \n",
    "#        self.conv2 = nn.Conv2d(20, 20, kernel_size=3, padding=2)  #10*6*6 => 10* 4 * 4 (Maxpool => 10*2*2)\n",
    "#        self.conv3 = nn.Conv2d(20, 20, kernel_size=3)\n",
    "#        self.conv4 = nn.Conv2d(20, 20, kernel_size=3)\n",
    "#        \n",
    "#        self.dense1 = nn.Linear(980, 50)\n",
    "#        \n",
    "#        self.conv5 = nn.Conv2d(20, 20, kernel_size=3, padding=2)\n",
    "#        self.conv6 = nn.Conv2d(20, 20, kernel_size=3, padding=2)\n",
    "#        self.conv7 = nn.Conv2d(20, 20, kernel_size=3)\n",
    "#        self.conv8 = nn.Conv2d(20, 20, kernel_size=3)\n",
    "#        \n",
    "#        self.dense2 = nn.Linear(980, 50)\n",
    "#        \n",
    "#        self.pred = nn.Linear(50, 1)\n",
    "#        \n",
    "#        \n",
    "#    def forward(self, x):\n",
    "#        x = F.relu(self.conv1(x))\n",
    "#        x = F.relu(self.conv2(x))\n",
    "#        x = F.relu(self.conv3(x))\n",
    "#        x = F.relu(self.conv4(x))\n",
    "#        \n",
    "#        self.pred1 = torch.flatten(F.max_pool2d(x, kernel_size = 2), 1)\n",
    "#        self.pred1 = F.relu(self.dense1(self.pred1))\n",
    "#        self.pred1 = torch.flatten(F.sigmoid(self.pred(self.pred1)))\n",
    "#        \n",
    "#        x = F.relu(self.conv5(x))\n",
    "#        x = F.relu(self.conv6(x))\n",
    "#        x = F.relu(self.conv7(x))\n",
    "#        x = F.relu(self.conv8(x))\n",
    "#        \n",
    "#        self.pred2 = torch.flatten(F.max_pool2d(x, kernel_size = 2), 1)\n",
    "#        self.pred2 = F.relu(self.dense2(self.pred2))\n",
    "#        self.pred2 = torch.flatten(F.sigmoid(self.pred(self.pred2)))\n",
    "#        \n",
    "#        return self.pred2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_target, epochs, optimizer, loss_function = nn.BCELoss(), batch_size=10):\n",
    "\n",
    "    model.train()\n",
    "    losses = []\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        sum_loss = 0\n",
    "        \n",
    "        for x_batch, y_batch in zip(x_train.split(batch_size),\n",
    "                                    y_train.split(batch_size)):\n",
    "            \n",
    "            output = model(x_batch)\n",
    "            loss = loss_function(output, y_batch.float())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            sum_loss = sum_loss + loss.item()\n",
    "            \n",
    "            \n",
    "        losses.append(sum_loss)\n",
    "        print(\"Epoch %i : loss %.2f\" % (e, sum_loss), end = \"\\r\")\n",
    "        \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_auxiliary_model(model, train_input, train_target,\n",
    "                          epochs, optimizer, loss_function = nn.BCELoss(), batch_size=10):\n",
    "    # Inspired by exercise corrige \n",
    "    model.train()\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        sum_loss = 0\n",
    "        sum_loss_ = 0\n",
    "        \n",
    "        for x_batch, y_batch in zip(x_train.split(batch_size),\n",
    "                                                    y_train.split(batch_size)):\n",
    "            \n",
    "            output, output_ = model(x_batch)\n",
    "            \n",
    "            auxiliary_loss = loss_function(output_, y_batch.float())\n",
    "            loss_final     = loss_function(output , y_batch.float())\n",
    "            \n",
    "            loss_total = loss_final + 0.5*(auxiliary_loss)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_total.backward()  \n",
    "            optimizer.step()\n",
    "            \n",
    "            sum_loss_ += auxiliary_loss.item()\n",
    "            sum_loss  += loss_final.item()\n",
    "            \n",
    "            \n",
    "        losses.append(sum_loss)\n",
    "        print(\"Epoch %i: loss_F %.2f --- loss_Int %.2f \" \\\n",
    "              % (e,sum_loss, sum_loss_), end=\"\\r\")  \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_auxiliary_model_WS(model, train_input, train_target, digit_target,\n",
    "                          epochs, optimizer, loss_function = nn.BCELoss(), batch_size=10):\n",
    "    # Inspired by exercise corrige \n",
    "    model.train()\n",
    "    \n",
    "    losses = []\n",
    "    digit_loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        sum_loss = 0\n",
    "        sum_loss_digit1 = 0\n",
    "        sum_loss_digit2 = 0\n",
    "        \n",
    "        for x_batch, y_batch, y_digit_batch in zip(x_train.split(batch_size),\n",
    "                                                    y_train.split(batch_size),\n",
    "                                                    digit_target.split(batch_size)):\n",
    "            \n",
    "            output,d1,d2 = model(x_batch)\n",
    "\n",
    "            loss_digit1 = digit_loss(d1, y_digit_batch[..., 0])\n",
    "            loss_digit2 = digit_loss(d2, y_digit_batch[..., 1])\n",
    "            loss_final  = loss_function(output, y_batch.float())\n",
    "            \n",
    "            loss_total = loss_final + 0.5*(loss_digit1 + loss_digit2)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_total.backward()  \n",
    "            optimizer.step()\n",
    "            \n",
    "            sum_loss_digit1 += loss_digit1.item()\n",
    "            sum_loss_digit2 += loss_digit2.item()\n",
    "            sum_loss += loss_final.item()\n",
    "            \n",
    "            \n",
    "        losses.append(sum_loss)\n",
    "        print(\"Epoch %i: loss %.2f --- loss_d1 %.2f --- loss_d2 %.2f\" \\\n",
    "              % (e,sum_loss, sum_loss_digit1, sum_loss_digit2), end=\"\\r\")  \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def train_auxiliary_model_2(model, train_input, train_target, digit_target,\n",
    "#                          epochs, optimizer, optimizer_digit, loss_function = nn.BCELoss(), batch_size=10):\n",
    "#    # Inspired by exercise corrige \n",
    "#    model.train()\n",
    "#    \n",
    "#    losses = []\n",
    "#    digit_loss = nn.CrossEntropyLoss()\n",
    "#    \n",
    "#    for e in range(epochs):\n",
    "#        sum_loss = 0\n",
    "#        sum_loss_digit1 = 0\n",
    "#        sum_loss_digit2 = 0\n",
    "#        \n",
    "#        for x_batch, y_batch, y_digit_batch in zip(x_train.split(batch_size),\n",
    "#                                                    y_train.split(batch_size),\n",
    "#                                                    digit_target.split(batch_size)):\n",
    "#            \n",
    "#            output = model(x_batch)\n",
    "#            \n",
    "#            loss1 = digit_loss(model.digits1, y_digit_batch[..., 0])\n",
    "#            loss2 = digit_loss(model.digits2, y_digit_batch[..., 1])\n",
    "#            \n",
    "#            loss_digits = loss1 + loss2\n",
    "#            loss_usual  = loss_function(output, y_batch.float())\n",
    "#\n",
    "#            optimizer.zero_grad()         \n",
    "#            loss_usual.backward(retain_graph=True)  \n",
    "#            optimizer.step()\n",
    "#            \n",
    "#            optimizer_digit.zero_grad()\n",
    "#            loss_digits.backward()\n",
    "#            optimizer_digit.step()\n",
    "#            \n",
    "#            sum_loss_digit1 += loss1.item()\n",
    "#            sum_loss_digit2 += loss2.item()\n",
    "#            sum_loss += loss_usual.item()\n",
    "#            \n",
    "#            \n",
    "#        losses.append(sum_loss)\n",
    "#        print(\"Epoch %i : loss %.2f --- loss_digit1 %.2f --- loss_digit2 %.2f\" \\\n",
    "#              % (e,sum_loss, sum_loss_digit1, sum_loss_digit2), end=\"\\r\")\n",
    "#        \n",
    "#    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def evaluate_model_2(model, test_input, test_target):\n",
    "#    model.eval()\n",
    "#    criterion = nn.BCELoss()\n",
    "#    preds_proba = model(test_input).view(-1)\n",
    "#    preds = preds_proba.masked_fill((preds_proba > 0.5), 1).masked_fill((preds_proba<0.5), 0)\n",
    "#    \n",
    "#    loss = criterion(preds_proba, test_target.float()).item()\n",
    "#    accuracy = (preds.float() == test_target.float()).sum().item()/preds.size(0)\n",
    "#    #accuracy = sum([pred == truth for pred, truth in zip(preds, test_target)])\n",
    "#    return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_input, test_target):\n",
    "    model.eval()\n",
    "    out = model(test_input) \n",
    "    preds_proba = out.view(-1)   \n",
    "    preds = preds_proba.masked_fill((preds_proba > 0.5), 1).masked_fill((preds_proba<0.5), 0)\n",
    "    accuracy = (preds.float() == test_target.float()).sum().item()/preds.size(0)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_tuple(model, test_input, test_target):\n",
    "    model.eval()\n",
    "    out = model(test_input)[0]       # [0] to catch the final output in case of models with auxilliary losses for which \n",
    "    preds_proba = out.view(-1)                           # intermediate results are returned \n",
    "    preds = preds_proba.masked_fill((preds_proba > 0.5), 1).masked_fill((preds_proba<0.5), 0)\n",
    "    accuracy = (preds.float() == test_target.float()).sum().item()/preds.size(0)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_model(model_name, build_model, auxiliary = False, weight_sharing = False):\n",
    "    ################################ TRAINING PARAMETERS ################################################ \n",
    "\n",
    "    number_training = 10\n",
    "    epochs = 25\n",
    "\n",
    "    #losses = [] <TODO> : usefulness of losses list ?\n",
    "    train_losses = []\n",
    "    accuracies = []\n",
    "    times = []\n",
    "\n",
    "    ################################ TRAINING  ################################################ \n",
    "\n",
    "    print(\"Starting %i training of %i epochs, with model '%s' containing %i parameters. \\n\" % \n",
    "          (number_training, epochs, model_name, number_parameters(build_model())))\n",
    "\n",
    "    for i_train in range(number_training):  \n",
    "        start = time.time()\n",
    "\n",
    "        model = build_model()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        indices_shuffle = torch.randperm(N)\n",
    "\n",
    "        if not auxiliary :\n",
    "            train_loss = train_model(model, x_train[indices_shuffle], y_train[indices_shuffle], epochs = epochs,\n",
    "                                                                         optimizer=optimizer,batch_size = 50)\n",
    "            accuracy = evaluate_model(model, x_test, y_test)\n",
    "\n",
    "        elif auxiliary and not weight_sharing:\n",
    "            train_loss = train_auxiliary_model(model,x_train[indices_shuffle], y_train[indices_shuffle], epochs = epochs,\n",
    "                                                                         optimizer=optimizer, batch_size = 50)\n",
    "            accuracy = evaluate_model_tuple(model, x_test, y_test)\n",
    "\n",
    "        elif (auxiliary and weight_sharing):\n",
    "            train_loss = train_auxiliary_model_WS(model,x_train[indices_shuffle],y_train[indices_shuffle], y_train_classes[indices_shuffle],epochs = epochs,\n",
    "                                                                          optimizer=optimizer,batch_size = 50)\n",
    "            accuracy = evaluate_model_tuple(model, x_test, y_test)\n",
    "\n",
    "        #accuracy = evaluate_model(model, x_test, y_test)\n",
    "        accuracy*=100\n",
    "        print(\"Attempt\", i_train + 1, \"- accuracy %.2f%%\"%accuracy)\n",
    "        #losses.append(loss)\n",
    "        #train_losses.append(train_loss)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "        times.append(time.time() - start)\n",
    "\n",
    "    print(\"\\nExperiment results :\")\n",
    "    #print(\"Loss mean : %.2f (%.3f)\" % (mean(losses), var(losses)))\n",
    "    print(\"Accuracy mean : %.2f%% (%.1f)\" % (mean(accuracies), var(accuracies)))\n",
    "    print(\"Average training time : %.1f seconds (%.1f)\\n\\n\" % (mean(times), var(times)))\n",
    "    \n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "model_list = [('Simple Net', model_0, False, False),\n",
    "             ('Auxiliary Loss', model_auxiliary_loss, True, False),\n",
    "             ('Weight Sharing', model_weight_sharing, False, True),\n",
    "             ('Auxiliary Loss + Weight Sharing', model_weight_sharing_with_auxiliary_loss, True, True),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 10 training of 25 epochs, with model 'Simple Net 2' containing 61935 parameters. \n",
      "\n",
      "Attempt 1 - accuracy 80.80%\n",
      "Attempt 2 - accuracy 77.80%\n",
      "Attempt 3 - accuracy 79.70%\n",
      "Attempt 4 - accuracy 80.30%\n",
      "Attempt 5 - accuracy 76.50%\n",
      "Attempt 6 - accuracy 79.70%\n",
      "Attempt 7 - accuracy 81.90%\n",
      "Attempt 8 - accuracy 77.60%\n",
      "Attempt 9 - accuracy 77.90%\n",
      "Attempt 10 - accuracy 74.40%\n",
      "\n",
      "Experiment results :\n",
      "Accuracy mean : 78.66% (4.5)\n",
      "Average training time : 1.1 seconds (0.0)\n"
     ]
    }
   ],
   "source": [
    "model_list = [('Simple Net 2', model_0, False, False)]\n",
    "\n",
    "for model_params in model_list :\n",
    "    results.append((experiment_model(*model_params), model_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results comparision between models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for result, model_params in results:\n",
    "    plt.plot(result, label = model_params[0])\n",
    "    plt.legend()\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ CHOICE OF THE MODEL ################################################ \n",
    "\n",
    "auxiliary      = False\n",
    "weight_sharing = False\n",
    "\n",
    "\n",
    "if (not auxiliary) and (not weight_sharing):  # model will be\n",
    "    md = 'Simple Net'\n",
    "    build_model = model_0                        # MLP\n",
    "    #build_model = model_1                       # simple CNN\n",
    "    #build_model = model_2                       # complex CNN\n",
    "    \n",
    "\n",
    "if auxiliary:                                 # model will be \n",
    "    md = 'Auxiliary Loss'  \n",
    "    build_model = model_auxiliary_loss           # CNN with intermediate output for auxiliary loss\n",
    "                                                 # (useful for deep NN)   \n",
    "\n",
    "if weight_sharing:                            # model will be\n",
    "    md = 'Weight Sharing'\n",
    "    build_model = model_weight_sharing            # identical and independant treatment of each image  \n",
    "    \n",
    "    \n",
    "if (auxiliary and weight_sharing):            # model will be  \n",
    "    md = 'Auxiliary Loss + Weight Sharing'\n",
    "    build_model = model_weight_sharing_with_auxiliary_loss    # identical and independant treatment of each image  \n",
    "                                                              # with intermediate output of digit prediction \n",
    "                                                              # for auxiliary losses (per digit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
