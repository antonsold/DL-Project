{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Loss: 0.279916\n",
      "Epoch: 1\n",
      "Loss: 0.250569\n",
      "Epoch: 2\n",
      "Loss: 0.250273\n",
      "Epoch: 3\n",
      "Loss: 0.249985\n",
      "Epoch: 4\n",
      "Loss: 0.249688\n",
      "Epoch: 5\n",
      "Loss: 0.249378\n",
      "Epoch: 6\n",
      "Loss: 0.249045\n",
      "Epoch: 7\n",
      "Loss: 0.248687\n",
      "Epoch: 8\n",
      "Loss: 0.248304\n",
      "Epoch: 9\n",
      "Loss: 0.247880\n",
      "Epoch: 10\n",
      "Loss: 0.247435\n",
      "Epoch: 11\n",
      "Loss: 0.246940\n",
      "Epoch: 12\n",
      "Loss: 0.246412\n",
      "Epoch: 13\n",
      "Loss: 0.245850\n",
      "Epoch: 14\n",
      "Loss: 0.245235\n",
      "Epoch: 15\n",
      "Loss: 0.244558\n",
      "Epoch: 16\n",
      "Loss: 0.243791\n",
      "Epoch: 17\n",
      "Loss: 0.242935\n",
      "Epoch: 18\n",
      "Loss: 0.241962\n",
      "Epoch: 19\n",
      "Loss: 0.240878\n",
      "Epoch: 20\n",
      "Loss: 0.239617\n",
      "Epoch: 21\n",
      "Loss: 0.238198\n",
      "Epoch: 22\n",
      "Loss: 0.236557\n",
      "Epoch: 23\n",
      "Loss: 0.234634\n",
      "Epoch: 24\n",
      "Loss: 0.232423\n",
      "Epoch: 25\n",
      "Loss: 0.229846\n",
      "Epoch: 26\n",
      "Loss: 0.226811\n",
      "Epoch: 27\n",
      "Loss: 0.223316\n",
      "Epoch: 28\n",
      "Loss: 0.219236\n",
      "Epoch: 29\n",
      "Loss: 0.214368\n",
      "Epoch: 30\n",
      "Loss: 0.208875\n",
      "Epoch: 31\n",
      "Loss: 0.204957\n",
      "Epoch: 32\n",
      "Loss: 0.220138\n",
      "Epoch: 33\n",
      "Loss: 0.202162\n",
      "Epoch: 34\n",
      "Loss: 0.205539\n",
      "Epoch: 35\n",
      "Loss: 0.194697\n",
      "Epoch: 36\n",
      "Loss: 0.189094\n",
      "Epoch: 37\n",
      "Loss: 0.179504\n",
      "Epoch: 38\n",
      "Loss: 0.176743\n",
      "Epoch: 39\n",
      "Loss: 0.165860\n",
      "Epoch: 40\n",
      "Loss: 0.165358\n",
      "Epoch: 41\n",
      "Loss: 0.134397\n",
      "Epoch: 42\n",
      "Loss: 0.186224\n",
      "Epoch: 43\n",
      "Loss: 0.158345\n",
      "Epoch: 44\n",
      "Loss: 0.147476\n",
      "Epoch: 45\n",
      "Loss: 0.150242\n",
      "Epoch: 46\n",
      "Loss: 0.139084\n",
      "Epoch: 47\n",
      "Loss: 0.138631\n",
      "Epoch: 48\n",
      "Loss: 0.129831\n",
      "Epoch: 49\n",
      "Loss: 0.130840\n",
      "Epoch: 50\n",
      "Loss: 0.124350\n",
      "Epoch: 51\n",
      "Loss: 0.123466\n",
      "Epoch: 52\n",
      "Loss: 0.116458\n",
      "Epoch: 53\n",
      "Loss: 0.115423\n",
      "Epoch: 54\n",
      "Loss: 0.109844\n",
      "Epoch: 55\n",
      "Loss: 0.108477\n",
      "Epoch: 56\n",
      "Loss: 0.106168\n",
      "Epoch: 57\n",
      "Loss: 0.104044\n",
      "Epoch: 58\n",
      "Loss: 0.102103\n",
      "Epoch: 59\n",
      "Loss: 0.097674\n",
      "Epoch: 60\n",
      "Loss: 0.097364\n",
      "Epoch: 61\n",
      "Loss: 0.094234\n",
      "Epoch: 62\n",
      "Loss: 0.094456\n",
      "Epoch: 63\n",
      "Loss: 0.090008\n",
      "Epoch: 64\n",
      "Loss: 0.090866\n",
      "Epoch: 65\n",
      "Loss: 0.087344\n",
      "Epoch: 66\n",
      "Loss: 0.085927\n",
      "Epoch: 67\n",
      "Loss: 0.085919\n",
      "Epoch: 68\n",
      "Loss: 0.084614\n",
      "Epoch: 69\n",
      "Loss: 0.081534\n",
      "Epoch: 70\n",
      "Loss: 0.081270\n",
      "Epoch: 71\n",
      "Loss: 0.081950\n",
      "Epoch: 72\n",
      "Loss: 0.081690\n",
      "Epoch: 73\n",
      "Loss: 0.080377\n",
      "Epoch: 74\n",
      "Loss: 0.080415\n",
      "Epoch: 75\n",
      "Loss: 0.079157\n",
      "Epoch: 76\n",
      "Loss: 0.078245\n",
      "Epoch: 77\n",
      "Loss: 0.077170\n",
      "Epoch: 78\n",
      "Loss: 0.076061\n",
      "Epoch: 79\n",
      "Loss: 0.076031\n",
      "Epoch: 80\n",
      "Loss: 0.075082\n",
      "Epoch: 81\n",
      "Loss: 0.073961\n",
      "Epoch: 82\n",
      "Loss: 0.073001\n",
      "Epoch: 83\n",
      "Loss: 0.072543\n",
      "Epoch: 84\n",
      "Loss: 0.071969\n",
      "Epoch: 85\n",
      "Loss: 0.070978\n",
      "Epoch: 86\n",
      "Loss: 0.070603\n",
      "Epoch: 87\n",
      "Loss: 0.070238\n",
      "Epoch: 88\n",
      "Loss: 0.069951\n",
      "Epoch: 89\n",
      "Loss: 0.067868\n",
      "Epoch: 90\n",
      "Loss: 0.066815\n",
      "Epoch: 91\n",
      "Loss: 0.066475\n",
      "Epoch: 92\n",
      "Loss: 0.065205\n",
      "Epoch: 93\n",
      "Loss: 0.064594\n",
      "Epoch: 94\n",
      "Loss: 0.062680\n",
      "Epoch: 95\n",
      "Loss: 0.065856\n",
      "Epoch: 96\n",
      "Loss: 0.065594\n",
      "Epoch: 97\n",
      "Loss: 0.064191\n",
      "Epoch: 98\n",
      "Loss: 0.064324\n",
      "Epoch: 99\n",
      "Loss: 0.064224\n",
      "Epoch: 100\n",
      "Loss: 0.063381\n",
      "Epoch: 101\n",
      "Loss: 0.061998\n",
      "Epoch: 102\n",
      "Loss: 0.061829\n",
      "Epoch: 103\n",
      "Loss: 0.062628\n",
      "Epoch: 104\n",
      "Loss: 0.061094\n",
      "Epoch: 105\n",
      "Loss: 0.060039\n",
      "Epoch: 106\n",
      "Loss: 0.059751\n",
      "Epoch: 107\n",
      "Loss: 0.059588\n",
      "Epoch: 108\n",
      "Loss: 0.059391\n",
      "Epoch: 109\n",
      "Loss: 0.059279\n",
      "Epoch: 110\n",
      "Loss: 0.058819\n",
      "Epoch: 111\n",
      "Loss: 0.057876\n",
      "Epoch: 112\n",
      "Loss: 0.057189\n",
      "Epoch: 113\n",
      "Loss: 0.057305\n",
      "Epoch: 114\n",
      "Loss: 0.055802\n",
      "Epoch: 115\n",
      "Loss: 0.055888\n",
      "Epoch: 116\n",
      "Loss: 0.056441\n",
      "Epoch: 117\n",
      "Loss: 0.055834\n",
      "Epoch: 118\n",
      "Loss: 0.056479\n",
      "Epoch: 119\n",
      "Loss: 0.055815\n",
      "Epoch: 120\n",
      "Loss: 0.054639\n",
      "Epoch: 121\n",
      "Loss: 0.053868\n",
      "Epoch: 122\n",
      "Loss: 0.052226\n",
      "Epoch: 123\n",
      "Loss: 0.052770\n",
      "Epoch: 124\n",
      "Loss: 0.050973\n",
      "Epoch: 125\n",
      "Loss: 0.050056\n",
      "Epoch: 126\n",
      "Loss: 0.050272\n",
      "Epoch: 127\n",
      "Loss: 0.049687\n",
      "Epoch: 128\n",
      "Loss: 0.048537\n",
      "Epoch: 129\n",
      "Loss: 0.048721\n",
      "Epoch: 130\n",
      "Loss: 0.050223\n",
      "Epoch: 131\n",
      "Loss: 0.048997\n",
      "Epoch: 132\n",
      "Loss: 0.048168\n",
      "Epoch: 133\n",
      "Loss: 0.048982\n",
      "Epoch: 134\n",
      "Loss: 0.049477\n",
      "Epoch: 135\n",
      "Loss: 0.048511\n",
      "Epoch: 136\n",
      "Loss: 0.047794\n",
      "Epoch: 137\n",
      "Loss: 0.047084\n",
      "Epoch: 138\n",
      "Loss: 0.046476\n",
      "Epoch: 139\n",
      "Loss: 0.046621\n",
      "Epoch: 140\n",
      "Loss: 0.046962\n",
      "Epoch: 141\n",
      "Loss: 0.046296\n",
      "Epoch: 142\n",
      "Loss: 0.046246\n",
      "Epoch: 143\n",
      "Loss: 0.045948\n",
      "Epoch: 144\n",
      "Loss: 0.046171\n",
      "Epoch: 145\n",
      "Loss: 0.045751\n",
      "Epoch: 146\n",
      "Loss: 0.045666\n",
      "Epoch: 147\n",
      "Loss: 0.045644\n",
      "Epoch: 148\n",
      "Loss: 0.045335\n",
      "Epoch: 149\n",
      "Loss: 0.045867\n",
      "Epoch: 150\n",
      "Loss: 0.044669\n",
      "Epoch: 151\n",
      "Loss: 0.044866\n",
      "Epoch: 152\n",
      "Loss: 0.043809\n",
      "Epoch: 153\n",
      "Loss: 0.044350\n",
      "Epoch: 154\n",
      "Loss: 0.044343\n",
      "Epoch: 155\n",
      "Loss: 0.044139\n",
      "Epoch: 156\n",
      "Loss: 0.043056\n",
      "Epoch: 157\n",
      "Loss: 0.043186\n",
      "Epoch: 158\n",
      "Loss: 0.044468\n",
      "Epoch: 159\n",
      "Loss: 0.042815\n",
      "Epoch: 160\n",
      "Loss: 0.042262\n",
      "Epoch: 161\n",
      "Loss: 0.041714\n",
      "Epoch: 162\n",
      "Loss: 0.041486\n",
      "Epoch: 163\n",
      "Loss: 0.044182\n",
      "Epoch: 164\n",
      "Loss: 0.045001\n",
      "Epoch: 165\n",
      "Loss: 0.044400\n",
      "Epoch: 166\n",
      "Loss: 0.041622\n",
      "Epoch: 167\n",
      "Loss: 0.040821\n",
      "Epoch: 168\n",
      "Loss: 0.040662\n",
      "Epoch: 169\n",
      "Loss: 0.040603\n",
      "Epoch: 170\n",
      "Loss: 0.040467\n",
      "Epoch: 171\n",
      "Loss: 0.043187\n",
      "Epoch: 172\n",
      "Loss: 0.043667\n",
      "Epoch: 173\n",
      "Loss: 0.041205\n",
      "Epoch: 174\n",
      "Loss: 0.040089\n",
      "Epoch: 175\n",
      "Loss: 0.038923\n",
      "Epoch: 176\n",
      "Loss: 0.039096\n",
      "Epoch: 177\n",
      "Loss: 0.039362\n",
      "Epoch: 178\n",
      "Loss: 0.039315\n",
      "Epoch: 179\n",
      "Loss: 0.039143\n",
      "Epoch: 180\n",
      "Loss: 0.039728\n",
      "Epoch: 181\n",
      "Loss: 0.040481\n",
      "Epoch: 182\n",
      "Loss: 0.039110\n",
      "Epoch: 183\n",
      "Loss: 0.038270\n",
      "Epoch: 184\n",
      "Loss: 0.038477\n",
      "Epoch: 185\n",
      "Loss: 0.038750\n",
      "Epoch: 186\n",
      "Loss: 0.039080\n",
      "Epoch: 187\n",
      "Loss: 0.038890\n",
      "Epoch: 188\n",
      "Loss: 0.038362\n",
      "Epoch: 189\n",
      "Loss: 0.038176\n",
      "Epoch: 190\n",
      "Loss: 0.038209\n",
      "Epoch: 191\n",
      "Loss: 0.038574\n",
      "Epoch: 192\n",
      "Loss: 0.038353\n",
      "Epoch: 193\n",
      "Loss: 0.038227\n",
      "Epoch: 194\n",
      "Loss: 0.038377\n",
      "Epoch: 195\n",
      "Loss: 0.038265\n",
      "Epoch: 196\n",
      "Loss: 0.040985\n",
      "Epoch: 197\n",
      "Loss: 0.036886\n",
      "Epoch: 198\n",
      "Loss: 0.037162\n",
      "Epoch: 199\n",
      "Loss: 0.043305\n",
      "Epoch: 200\n",
      "Loss: 0.036279\n",
      "Epoch: 201\n",
      "Loss: 0.036846\n",
      "Epoch: 202\n",
      "Loss: 0.038077\n",
      "Epoch: 203\n",
      "Loss: 0.041644\n",
      "Epoch: 204\n",
      "Loss: 0.035582\n",
      "Epoch: 205\n",
      "Loss: 0.036281\n",
      "Epoch: 206\n",
      "Loss: 0.037683\n",
      "Epoch: 207\n",
      "Loss: 0.041511\n",
      "Epoch: 208\n",
      "Loss: 0.036191\n",
      "Epoch: 209\n",
      "Loss: 0.036450\n",
      "Epoch: 210\n",
      "Loss: 0.038977\n",
      "Epoch: 211\n",
      "Loss: 0.038100\n",
      "Epoch: 212\n",
      "Loss: 0.036327\n",
      "Epoch: 213\n",
      "Loss: 0.034756\n",
      "Epoch: 214\n",
      "Loss: 0.033960\n",
      "Epoch: 215\n",
      "Loss: 0.037187\n",
      "Epoch: 216\n",
      "Loss: 0.034506\n",
      "Epoch: 217\n",
      "Loss: 0.035017\n",
      "Epoch: 218\n",
      "Loss: 0.034311\n",
      "Epoch: 219\n",
      "Loss: 0.033643\n",
      "Epoch: 220\n",
      "Loss: 0.038163\n",
      "Epoch: 221\n",
      "Loss: 0.033655\n",
      "Epoch: 222\n",
      "Loss: 0.036255\n",
      "Epoch: 223\n",
      "Loss: 0.036232\n",
      "Epoch: 224\n",
      "Loss: 0.033544\n",
      "Epoch: 225\n",
      "Loss: 0.033042\n",
      "Epoch: 226\n",
      "Loss: 0.031964\n",
      "Epoch: 227\n",
      "Loss: 0.035852\n",
      "Epoch: 228\n",
      "Loss: 0.038263\n",
      "Epoch: 229\n",
      "Loss: 0.038346\n",
      "Epoch: 230\n",
      "Loss: 0.036264\n",
      "Epoch: 231\n",
      "Loss: 0.032485\n",
      "Epoch: 232\n",
      "Loss: 0.031279\n",
      "Epoch: 233\n",
      "Loss: 0.031764\n",
      "Epoch: 234\n",
      "Loss: 0.032169\n",
      "Epoch: 235\n",
      "Loss: 0.033315\n",
      "Epoch: 236\n",
      "Loss: 0.039863\n",
      "Epoch: 237\n",
      "Loss: 0.031061\n",
      "Epoch: 238\n",
      "Loss: 0.031576\n",
      "Epoch: 239\n",
      "Loss: 0.032894\n",
      "Epoch: 240\n",
      "Loss: 0.032848\n",
      "Epoch: 241\n",
      "Loss: 0.034186\n",
      "Epoch: 242\n",
      "Loss: 0.031562\n",
      "Epoch: 243\n",
      "Loss: 0.031229\n",
      "Epoch: 244\n",
      "Loss: 0.030670\n",
      "Epoch: 245\n",
      "Loss: 0.031972\n",
      "Epoch: 246\n",
      "Loss: 0.036809\n",
      "Epoch: 247\n",
      "Loss: 0.030113\n",
      "Epoch: 248\n",
      "Loss: 0.032042\n",
      "Epoch: 249\n",
      "Loss: 0.037032\n",
      "Train accuracy: 0.925000\n",
      "Test accuracy: 0.909000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from modules import module as md\n",
    "from modules import model as m\n",
    "from modules import generate as gen\n",
    "torch.set_grad_enabled(False)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "sample_size = 1000\n",
    "\n",
    "\n",
    "train_input, train_target = gen.generate_set(sample_size)\n",
    "test_input, test_target = gen.generate_set(sample_size)\n",
    "\n",
    "\n",
    "layers = [md.Linear(2, 25), md.ReLU(), md.Linear(25, 25), md.ReLU(), md.Linear(25, 25),\n",
    "          md.ReLU(), md.Linear(25, 2)]\n",
    "model = m.Model(layers)\n",
    "\n",
    "\n",
    "m.train_model(model, train_input, train_target)\n",
    "print(\"Train accuracy: %f\" % m.accuracy(train_target, model(train_input)))\n",
    "print(\"Test accuracy: %f\" % m.accuracy(test_target, model(test_input)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
